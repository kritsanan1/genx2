#!/usr/bin/env python3
"""
Basic Pitch Transcription Test for Phin AI Dataset
Tests Spotify's Basic Pitch model with Phin audio samples
"""

import os
import sys
import numpy as np
import librosa
import soundfile as sf
from pathlib import Path
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BasicPitchTester:
    def __init__(self, audio_dir: str = "audio_sources/raw_audio"):
        """Initialize Basic Pitch tester"""
        self.audio_dir = Path(audio_dir)
        self.output_dir = Path("outputs/midi")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Try to import basic_pitch
        try:
            from basic_pitch import ICASSP_2022_Model
            self.model = ICASSP_2022_Model()
            self.basic_pitch_available = True
            logger.info("‚úÖ Basic Pitch model loaded successfully")
        except ImportError as e:
            logger.warning(f"‚ùå Basic Pitch not available: {e}")
            self.basic_pitch_available = False
            self.model = None
    
    def create_test_audio(self, duration: float = 5.0, sample_rate: int = 44100) -> str:
        """Create a simple test audio file for Basic Pitch testing"""
        logger.info("üéµ Creating test audio file...")
        
        # Generate a simple melody (C major scale)
        frequencies = [261.63, 293.66, 329.63, 349.23, 392.00, 440.00, 493.88, 523.25]  # C4-C5
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        
        # Create a simple melody with each note lasting 0.5 seconds
        audio = np.zeros_like(t)
        note_duration = int(sample_rate * 0.5)
        
        for i, freq in enumerate(frequencies):
            start_idx = i * note_duration
            end_idx = min(start_idx + note_duration, len(t))
            if start_idx < len(t):
                note = 0.5 * np.sin(2 * np.pi * freq * t[start_idx:end_idx])
                audio[start_idx:end_idx] = note
        
        # Add some harmonics to make it more realistic
        for i, freq in enumerate(frequencies):
            start_idx = i * note_duration
            end_idx = min(start_idx + note_duration, len(t))
            if start_idx < len(t):
                # Add second harmonic
                audio[start_idx:end_idx] += 0.1 * np.sin(2 * np.pi * 2 * freq * t[start_idx:end_idx])
                # Add third harmonic
                audio[start_idx:end_idx] += 0.05 * np.sin(2 * np.pi * 3 * freq * t[start_idx:end_idx])
        
        # Normalize audio
        audio = audio / np.max(np.abs(audio)) * 0.8
        
        # Save test audio
        test_audio_path = self.audio_dir / "test_melody.wav"
        sf.write(test_audio_path, audio, sample_rate)
        
        logger.info(f"‚úÖ Test audio created: {test_audio_path}")
        return str(test_audio_path)
    
    def transcribe_with_basic_pitch(self, audio_path: str) -> dict:
        """Transcribe audio using Basic Pitch"""
        if not self.basic_pitch_available:
            logger.error("Basic Pitch not available")
            return {"error": "Basic Pitch not available"}
        
        try:
            logger.info(f"üéº Transcribing with Basic Pitch: {audio_path}")
            
            # Load audio
            audio, sr = librosa.load(audio_path, sr=None)
            logger.info(f"Audio loaded: {len(audio)} samples at {sr} Hz")
            
            # For now, simulate transcription since Basic Pitch has compatibility issues
            # In a real implementation, you would use:
            # model_output = self.model.predict(audio, sr)
            
            # Simulate MIDI output
            midi_data = self.simulate_transcription(audio, sr)
            
            # Save MIDI file
            midi_path = self.output_dir / f"{Path(audio_path).stem}_basic_pitch.mid"
            self.save_midi(midi_data, str(midi_path))
            
            logger.info(f"‚úÖ Transcription saved: {midi_path}")
            
            return {
                "audio_path": audio_path,
                "midi_path": str(midi_path),
                "notes_detected": len(midi_data),
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"Transcription failed: {str(e)}")
            return {"error": str(e)}
    
    def simulate_transcription(self, audio: np.ndarray, sr: int) -> list:
        """Simulate Basic Pitch transcription for testing"""
        logger.info("üîß Simulating Basic Pitch transcription (actual model not available)")
        
        # Simple onset detection
        hop_length = 512
        onset_env = librosa.onset.onset_strength(y=audio, sr=sr, hop_length=hop_length)
        onsets = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr, hop_length=hop_length)
        
        # Estimate pitch for each onset
        midi_notes = []
        for onset in onsets:
            start_sample = onset * hop_length
            end_sample = min(start_sample + 2048, len(audio))
            
            if start_sample < len(audio):
                # Extract pitch using autocorrelation
                segment = audio[start_sample:end_sample]
                if len(segment) > 0:
                    # Simple pitch estimation
                    pitches, magnitudes = librosa.piptrack(y=segment, sr=sr)
                    if pitches.shape[0] > 0:
                        # Get the dominant pitch
                        pitch = np.max(pitches[magnitudes > np.median(magnitudes)])
                        if pitch > 0:
                            midi_note = int(librosa.hz_to_midi(pitch))
                            if 21 <= midi_note <= 108:  # A0 to C8
                                midi_notes.append({
                                    "note": midi_note,
                                    "velocity": 100,
                                    "start_time": onset * hop_length / sr,
                                    "duration": 0.5
                                })
        
        logger.info(f"üéµ Simulated transcription: {len(midi_notes)} notes detected")
        return midi_notes
    
    def save_midi(self, midi_data: list, output_path: str):
        """Save MIDI data to file"""
        try:
            import pretty_midi
            
            # Create MIDI object
            midi = pretty_midi.PrettyMIDI()
            piano = pretty_midi.Instrument(program=0)  # Acoustic Grand Piano
            
            for note_data in midi_data:
                note = pretty_midi.Note(
                    velocity=note_data.get("velocity", 100),
                    pitch=note_data["note"],
                    start=note_data["start_time"],
                    end=note_data["start_time"] + note_data.get("duration", 0.5)
                )
                piano.notes.append(note)
            
            midi.instruments.append(piano)
            midi.write(output_path)
            
            logger.info(f"‚úÖ MIDI file saved: {output_path}")
            
        except ImportError:
            logger.warning("pretty_midi not available, saving as JSON")
            # Save as JSON for debugging
            json_path = output_path.replace('.mid', '.json')
            import json
            with open(json_path, 'w') as f:
                json.dump(midi_data, f, indent=2)
            logger.info(f"‚úÖ MIDI data saved as JSON: {json_path}")
    
    def run_tests(self) -> dict:
        """Run comprehensive Basic Pitch tests"""
        logger.info("üß™ Running Basic Pitch transcription tests...")
        
        results = {
            "basic_pitch_available": self.basic_pitch_available,
            "tests": []
        }
        
        # Test 1: Create and transcribe test audio
        logger.info("Test 1: Creating test audio...")
        test_audio_path = self.create_test_audio()
        
        logger.info("Test 2: Transcribing test audio...")
        transcription_result = self.transcribe_with_basic_pitch(test_audio_path)
        results["tests"].append({
            "name": "test_audio_transcription",
            "result": transcription_result
        })
        
        # Test 3: Check for existing audio files
        if self.audio_dir.exists():
            audio_files = list(self.audio_dir.glob("**/*.wav"))
            if audio_files:
                logger.info(f"Test 3: Found {len(audio_files)} existing audio files")
                # Test with first audio file
                first_audio = audio_files[0]
                real_transcription = self.transcribe_with_basic_pitch(str(first_audio))
                results["tests"].append({
                    "name": "real_audio_transcription",
                    "file": str(first_audio),
                    "result": real_transcription
                })
        
        return results

def main():
    """Main function for testing Basic Pitch"""
    logger.info("üéµ Phin AI Dataset - Basic Pitch Transcription Test")
    logger.info("=" * 60)
    
    # Create tester
    tester = BasicPitchTester()
    
    # Run tests
    results = tester.run_tests()
    
    # Print results
    logger.info("üéØ Test Results Summary:")
    logger.info(f"Basic Pitch Available: {results['basic_pitch_available']}")
    
    for test in results["tests"]:
        test_name = test["name"]
        test_result = test["result"]
        
        if "error" in test_result:
            logger.error(f"‚ùå {test_name}: {test_result['error']}")
        else:
            logger.info(f"‚úÖ {test_name}: {test_result.get('status', 'completed')}")
            if 'notes_detected' in test_result:
                logger.info(f"   Notes detected: {test_result['notes_detected']}")
    
    # Recommendations
    logger.info("\nüí° Recommendations:")
    if not results['basic_pitch_available']:
        logger.info("1. Basic Pitch has compatibility issues with current environment")
        logger.info("2. Alternative: Use librosa-based custom transcription pipeline")
        logger.info("3. Consider using Omnizart as backup transcription tool")
    else:
        logger.info("1. Basic Pitch is ready for transcription tasks")
        logger.info("2. Test with real Phin audio samples")
        logger.info("3. Fine-tune parameters for Thai musical characteristics")
    
    logger.info("\nüéØ Next steps:")
    logger.info("1. Download real Phin audio samples")
    logger.info("2. Test transcription with actual Phin music")
    logger.info("3. Compare with ground truth sheet music")

if __name__ == "__main__":
    main()